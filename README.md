# GIANT-XRT方法根据图进行商品关联的预测

## 开篇引入

顾客购物所购买的商品之间往往具有一定程度的关联性, 换句话说, 顾客可能会更加倾向于同时购买几类有关联的商品. 如果可以对商品之间的关联有更加深刻的认识, 实体商家就可以优化商品的摆放, 而电商从业者则可以提供准确性和关联度更高的商品推送. 对业者而言, 了解商品购买之间的关联将有助于增加关联商品销量, 提升盈利; 对顾客而言, 也能提高选购的效率, 提升购物的体验. 因此, 进行商品关联的预测将是一个双赢的课题. 

本实验中, 我将尝试使用GIANT-XRT方法, 结合其他的优化方法来解决上述问题.

## 相关工作

- Kipf, Welling, Hamilton等人的研究中, 他们使用GNN, 将具有数字节点属性的图作为输入, 并以特定任务的方式训练它们, 来处理图相关的机器学习的问题.

- Hu, You, Velickovic, Kipf & Welling, Deng等人将自监督学习(SSL)和GNN一同使用. 这些工作背后的共同想法是探索由数字节点特征和图形拓扑结构提供的相关信息. 节点特征和图的拓扑结构提供的相关信息，这可以促进节点表示的改进和GNN初始化. 但是, 如何从文本、图像和音频信号等原始数据中实际获得数字节点特征这个关键问题, 经常被忽略掉. 

- Shen, Yu, Chang等人在文章中有分析过邻域预测和极端多标签分类（XMC）问题, 它适用于同亲图和异亲图，并建立了邻域预测和eXtom的联系. 该方法在每个节点的邻域可以使用二进制多标签（表示一个节点是否是邻居）进行编码, 而且, BERT模型是通过连续改进预测的邻域来进行微调的. 该方法不仅使我们能够利用XMC问题的高级求解器, 解决了图无关的特征提取,而且还可以对XMC问题进行理论研究, 并确定其在图的背景下的重要性. 

- Chiang等人发现了以端到端的方式联合训练BERT和GNN在实际操作中的缺陷. 由于GPU内存的限制, BERT过高的模型复杂度使得这样的组合在实践中难以实现. 同时他们还指出了用任意的小批处理量来训练这种方法的组合并不容易的事实. 
另一方面, Jiang等人发现XRTransformer架构可以自然地支持小批量训练,而且扩展性好. 因此本实验使用的是XRTTransformer的思路.

## 方法

### 问题定义

根据图数据进行商品关联的预测的问题, 更加具体来讲是根据两个商品的节点和边的数据判断两者是否关联的问题, 即最终的结果只有是否两个. 

### 数据

本实验的数据集采用Amazon的Ogbn-products数据集. 
该数据集是无指向，无权重的图. 
其中节点表示Amazon 上的商品, 商品共有 47 种类型. 边表示, 商品同时购买的关联关系. 
节点特征是通过从产品描述中提取词袋特征, Amazon对其进行主成分分析 (Principal Component Analysis), 最后将维数降至 100.

为了方便使用, 数据集本身提供了processed, mapping和embedding的数据. 
同时, 数据的划分, 不采用随机 90% 训练， 10% 测试的传统模式. 该数据集按照销售排名( 流行度 ) 将节点拆分为训练 / 验证 / 测试集. 其中, 排名前 8% 的产品进行训练, 排名第二的 2% 进行验证, 其余的用于测试. 三个部分都位于splite文件夹中. 

Raw文件夹中存放这原始的数据. 包含了edge, node-feat, node-label, num-edge-list, num-node-list. 

其中数据格式为:

- edge

```
0,152857
0,32104
0,23158
0,228358
...
```

- node-feat

```
0.031933263,-0.1958605,0.051996097,-0.06334871,-0.22986835,-0.022129532,0.40464723,-0.10793603,0.032561965,0.060270194,0.13269563,0.45855704,-0.09549294,0.2511796,-0.027464114,0.20436598,-0.065092035,0.28799063,0.015266046,0.13918501,-0.2739126,-0.1049344,-0.021357683,0.2757894,0.04562518,-0.31325325,-0.20204858,-0.2023845,-0.31768876,0.07928958,-0.10983908,0.21497923,-0.34562513,-0.22235885,-0.40740022,-0.10197799,-0.40941617,-0.0050209644,0.48593113,0.35642037,0.044606656,-0.0541052,0.14024858,0.32521355,0.021967093,-0.30192158,0.20702425,0.27723923,0.00012429977,0.21450363,-0.101871975,-0.014704957,0.44536516,-0.12549752,-0.08720419,-0.063674584,-0.08296194,-0.0387985,0.19938885,0.43433645,-0.15574497,0.10860939,-0.28591663,-0.7116335,-0.022232322,-0.116277166,-0.3184415,-0.05547596,0.030896178,0.3595624,0.2551715,0.21754548,0.21767096,-0.17638081,-0.013237791,-0.26136512,0.0062383697,0.16235061,-0.12374471,-0.13846652,-0.47884107,0.009011618,0.084543325,-0.25821444,-0.26492345,0.28033432,-0.22818153,0.08788001,-0.35572353,0.067761,-0.29939407,-0.18310812,0.50097805,0.40223902,0.11224879,-0.11269041,0.1417628,0.07669606,-0.3929545,-0.064784236
...
```

- node-label

```
0
1
2
3
3
4
5
...
```

- num-edge-list

```
61859140
```

- num-node-list

```
2449029
```

### 算法

针对上述的使用场景, 使用图这一数据结构将是最优的策略. 针对图进行机器学习, 需要涉及到图形神经网络. 图形神经网络(GNNs)在许多图学习任务上提供了最先进的性能，现在已经成为该领域的标准方法. 但是, 由于上文提到的标准的GNN存在的图不可知问题, 所以这里采用GIANT-XRT的方案来进行训练, 同时结合SAGN+SLE来优化准确率.

GIANT方法的全称是自监督图信息辅助节点特征提取方法, 使用极端多标签分类 (XMC) 的形式.  采用上文提到的 XR-Transformer 进行训练，使得编码器生成信息丰富的数值节点特征. 该方法基于标签特征 Z∈RL×d 构建了一个分层的标签聚类树进行范数归一化. 同时, 使用平衡的 kmeans 递归地划分标签集，并以自顶向下的方式生成分层标签集群树.
最后, 在GIANT的基础上, 我使用SAGN+SLE来优化模型的性能, 进一步提升GIANT的准确率.

## 环境配置和使用

### 环境配置

#### 安装Conda

```
wget https://repo.anaconda.com/archive/Anaconda3-2019.07-Linux-x86_64.sh
bash Anaconda3-2019.07-Linux-x86_64.sh
```

#### 创建虚拟环境

```
conda create -n "lab" python=3.8
conda activate lab
```

#### 进入虚拟环境

```
conda activate lab
```

#### 安装pytorch和其他运行库

```
conda install pytorch==1.9.0 cudatoolkit=10.2 -c pytorch
pip install libpecos==0.2.2
pip install torch-scatter==2.0.8
pip install torch-cluster==1.5.9
pip install torch-spline-conv==1.2.1
pip install torch-sparse==0.6.10
pip install torch-geometric
pip install ogb==1.3.2
pip install matplotlib
pip install seaborn
```

#### 检测安装情况

```
python -c "import torch; print('torch={}, cuda={}'.format(torch.__version__, torch.cuda.is_available()))"
```
```
python -c "import ogb; from ogb.graphproppred import PygGraphPropPredDataset; print(ogb.__version__)"
```

### 运行

#### 下载数据集

```
cd ./proc_data_xrt
bash download_data.sh ogbn-products
cd -
```

#### 纯GIANT方法

```
bash ./run_ogb_baselines.sh ogbn-products mlp
```

#### GIANT+SAGN+SLE

```
cd ./sagn_sle
bash Runexp_SAGN_SLE_ogbnproducts.sh
cd -
```

### 结果

#### 纯GIANT

|Highest Train | Highest Valid | Final Train | Final Test |
|---|---|---|---|
| 96.43 ± 0.29 | 92.14 ± 0.07 | 94.64 ± 0.40 | 80.47 ± 0.25 |

#### GIANT+SAGN+SLE


